Steps:   0%|          | 0/14000000 [00:00<?, ?it/s]
[TRAINING] Warmup - using fixed input image for now!
tensor([[[-3.1343e-01, -4.4757e-01, -8.2413e-03,  ...,  2.5421e-01,
          -3.2432e-02, -2.9603e-01],
         [ 1.4114e+00,  7.5773e-03, -4.2885e-01,  ...,  1.0365e+00,
          -6.7341e-01,  1.5006e+00],
         [ 1.8676e+00, -1.0888e+00, -1.0656e+00,  ...,  2.0319e+00,
          -1.1396e+00, -1.8952e-01],
         ...,
         [ 6.0629e-03, -1.4990e+00, -3.9075e-01,  ..., -1.7927e-01,
          -3.2250e-01, -1.5236e-02],
         [ 2.7658e-02, -1.5532e+00, -4.1507e-01,  ..., -4.4162e-01,
          -3.9632e-01,  1.9090e-01],
         [-7.0736e-02, -2.6132e+00, -1.0513e+00,  ...,  1.0083e-03,
          -5.0300e-01,  4.0608e-01]],

        [[-3.1343e-01, -4.4757e-01, -8.2413e-03,  ...,  2.5421e-01,
          -3.2432e-02, -2.9603e-01],
         [ 1.4114e+00,  7.5773e-03, -4.2885e-01,  ...,  1.0365e+00,
          -6.7341e-01,  1.5006e+00],
         [ 1.8676e+00, -1.0888e+00, -1.0656e+00,  ...,  2.0319e+00,
          -1.1396e+00, -1.8952e-01],
         ...,
         [ 6.0629e-03, -1.4990e+00, -3.9075e-01,  ..., -1.7927e-01,
          -3.2250e-01, -1.5236e-02],
         [ 2.7658e-02, -1.5532e+00, -4.1507e-01,  ..., -4.4162e-01,
          -3.9632e-01,  1.9090e-01],
         [-7.0736e-02, -2.6132e+00, -1.0513e+00,  ...,  1.0083e-03,
          -5.0300e-01,  4.0608e-01]],

        [[-3.1343e-01, -4.4757e-01, -8.2413e-03,  ...,  2.5421e-01,
          -3.2432e-02, -2.9603e-01],
         [ 1.4114e+00,  7.5773e-03, -4.2885e-01,  ...,  1.0365e+00,
          -6.7341e-01,  1.5006e+00],
         [ 1.8676e+00, -1.0888e+00, -1.0656e+00,  ...,  2.0319e+00,
          -1.1396e+00, -1.8952e-01],
         ...,
         [ 6.0629e-03, -1.4990e+00, -3.9075e-01,  ..., -1.7927e-01,
          -3.2250e-01, -1.5236e-02],
         [ 2.7658e-02, -1.5532e+00, -4.1507e-01,  ..., -4.4162e-01,
          -3.9632e-01,  1.9090e-01],
         [-7.0736e-02, -2.6132e+00, -1.0513e+00,  ...,  1.0083e-03,
          -5.0300e-01,  4.0608e-01]],

        ...,

        [[-3.1343e-01, -4.4757e-01, -8.2413e-03,  ...,  2.5421e-01,
          -3.2432e-02, -2.9603e-01],
         [ 1.4114e+00,  7.5773e-03, -4.2885e-01,  ...,  1.0365e+00,
          -6.7341e-01,  1.5006e+00],
         [ 1.8676e+00, -1.0888e+00, -1.0656e+00,  ...,  2.0319e+00,
          -1.1396e+00, -1.8952e-01],
         ...,
         [ 6.0629e-03, -1.4990e+00, -3.9075e-01,  ..., -1.7927e-01,
          -3.2250e-01, -1.5236e-02],
         [ 2.7658e-02, -1.5532e+00, -4.1507e-01,  ..., -4.4162e-01,
          -3.9632e-01,  1.9090e-01],
         [-7.0736e-02, -2.6132e+00, -1.0513e+00,  ...,  1.0083e-03,
          -5.0300e-01,  4.0608e-01]],

        [[-3.1343e-01, -4.4757e-01, -8.2413e-03,  ...,  2.5421e-01,
          -3.2432e-02, -2.9603e-01],
         [ 1.4114e+00,  7.5773e-03, -4.2885e-01,  ...,  1.0365e+00,
          -6.7341e-01,  1.5006e+00],
         [ 1.8676e+00, -1.0888e+00, -1.0656e+00,  ...,  2.0319e+00,
          -1.1396e+00, -1.8952e-01],
         ...,
         [ 6.0629e-03, -1.4990e+00, -3.9075e-01,  ..., -1.7927e-01,
          -3.2250e-01, -1.5236e-02],
         [ 2.7658e-02, -1.5532e+00, -4.1507e-01,  ..., -4.4162e-01,
          -3.9632e-01,  1.9090e-01],
         [-7.0736e-02, -2.6132e+00, -1.0513e+00,  ...,  1.0083e-03,
          -5.0300e-01,  4.0608e-01]],

        [[-3.1343e-01, -4.4757e-01, -8.2413e-03,  ...,  2.5421e-01,
          -3.2432e-02, -2.9603e-01],
         [ 1.4114e+00,  7.5773e-03, -4.2885e-01,  ...,  1.0365e+00,
          -6.7341e-01,  1.5006e+00],
         [ 1.8676e+00, -1.0888e+00, -1.0656e+00,  ...,  2.0319e+00,
          -1.1396e+00, -1.8952e-01],
         ...,
         [ 6.0629e-03, -1.4990e+00, -3.9075e-01,  ..., -1.7927e-01,
          -3.2250e-01, -1.5236e-02],
         [ 2.7658e-02, -1.5532e+00, -4.1507e-01,  ..., -4.4162e-01,
          -3.9632e-01,  1.9090e-01],
         [-7.0736e-02, -2.6132e+00, -1.0513e+00,  ...,  1.0083e-03,
          -5.0300e-01,  4.0608e-01]]], device='cuda:0')
tensor([[[-3.1343e-01, -4.4757e-01, -8.2413e-03,  ...,  2.5421e-01,
          -3.2432e-02, -2.9603e-01],
         [ 1.4114e+00,  7.5773e-03, -4.2885e-01,  ...,  1.0365e+00,
          -6.7341e-01,  1.5006e+00],
         [ 1.8676e+00, -1.0888e+00, -1.0656e+00,  ...,  2.0319e+00,
          -1.1396e+00, -1.8952e-01],
         ...,
         [ 6.0629e-03, -1.4990e+00, -3.9075e-01,  ..., -1.7927e-01,
          -3.2250e-01, -1.5236e-02],
         [ 2.7658e-02, -1.5532e+00, -4.1507e-01,  ..., -4.4162e-01,
          -3.9632e-01,  1.9090e-01],
         [-7.0736e-02, -2.6132e+00, -1.0513e+00,  ...,  1.0083e-03,
          -5.0300e-01,  4.0608e-01]],

        [[-3.1343e-01, -4.4757e-01, -8.2413e-03,  ...,  2.5421e-01,
          -3.2432e-02, -2.9603e-01],
         [ 1.4114e+00,  7.5773e-03, -4.2885e-01,  ...,  1.0365e+00,
          -6.7341e-01,  1.5006e+00],
         [ 1.8676e+00, -1.0888e+00, -1.0656e+00,  ...,  2.0319e+00,
          -1.1396e+00, -1.8952e-01],
         ...,
         [ 6.0629e-03, -1.4990e+00, -3.9075e-01,  ..., -1.7927e-01,
          -3.2250e-01, -1.5236e-02],
         [ 2.7658e-02, -1.5532e+00, -4.1507e-01,  ..., -4.4162e-01,
          -3.9632e-01,  1.9090e-01],
         [-7.0736e-02, -2.6132e+00, -1.0513e+00,  ...,  1.0083e-03,
          -5.0300e-01,  4.0608e-01]],

        [[-3.1343e-01, -4.4757e-01, -8.2413e-03,  ...,  2.5421e-01,
          -3.2432e-02, -2.9603e-01],
         [ 1.4114e+00,  7.5773e-03, -4.2885e-01,  ...,  1.0365e+00,
          -6.7341e-01,  1.5006e+00],
         [ 1.8676e+00, -1.0888e+00, -1.0656e+00,  ...,  2.0319e+00,
          -1.1396e+00, -1.8952e-01],
         ...,
         [ 6.0629e-03, -1.4990e+00, -3.9075e-01,  ..., -1.7927e-01,
          -3.2250e-01, -1.5236e-02],
         [ 2.7658e-02, -1.5532e+00, -4.1507e-01,  ..., -4.4162e-01,
          -3.9632e-01,  1.9090e-01],
         [-7.0736e-02, -2.6132e+00, -1.0513e+00,  ...,  1.0083e-03,
          -5.0300e-01,  4.0608e-01]],

        ...,

        [[-3.1343e-01, -4.4757e-01, -8.2413e-03,  ...,  2.5421e-01,
          -3.2432e-02, -2.9603e-01],
         [ 1.4114e+00,  7.5773e-03, -4.2885e-01,  ...,  1.0365e+00,
          -6.7341e-01,  1.5006e+00],
         [ 1.8676e+00, -1.0888e+00, -1.0656e+00,  ...,  2.0319e+00,
          -1.1396e+00, -1.8952e-01],
         ...,
         [ 6.0629e-03, -1.4990e+00, -3.9075e-01,  ..., -1.7927e-01,
          -3.2250e-01, -1.5236e-02],
         [ 2.7658e-02, -1.5532e+00, -4.1507e-01,  ..., -4.4162e-01,
          -3.9632e-01,  1.9090e-01],
         [-7.0736e-02, -2.6132e+00, -1.0513e+00,  ...,  1.0083e-03,
          -5.0300e-01,  4.0608e-01]],

        [[-3.1343e-01, -4.4757e-01, -8.2413e-03,  ...,  2.5421e-01,
          -3.2432e-02, -2.9603e-01],
         [ 1.4114e+00,  7.5773e-03, -4.2885e-01,  ...,  1.0365e+00,
          -6.7341e-01,  1.5006e+00],
         [ 1.8676e+00, -1.0888e+00, -1.0656e+00,  ...,  2.0319e+00,
          -1.1396e+00, -1.8952e-01],
         ...,
         [ 6.0629e-03, -1.4990e+00, -3.9075e-01,  ..., -1.7927e-01,
          -3.2250e-01, -1.5236e-02],
         [ 2.7658e-02, -1.5532e+00, -4.1507e-01,  ..., -4.4162e-01,
          -3.9632e-01,  1.9090e-01],
         [-7.0736e-02, -2.6132e+00, -1.0513e+00,  ...,  1.0083e-03,
          -5.0300e-01,  4.0608e-01]],

        [[-3.1343e-01, -4.4757e-01, -8.2413e-03,  ...,  2.5421e-01,
          -3.2432e-02, -2.9603e-01],
         [ 1.4114e+00,  7.5773e-03, -4.2885e-01,  ...,  1.0365e+00,
          -6.7341e-01,  1.5006e+00],
         [ 1.8676e+00, -1.0888e+00, -1.0656e+00,  ...,  2.0319e+00,
          -1.1396e+00, -1.8952e-01],
         ...,
         [ 6.0629e-03, -1.4990e+00, -3.9075e-01,  ..., -1.7927e-01,
          -3.2250e-01, -1.5236e-02],
         [ 2.7658e-02, -1.5532e+00, -4.1507e-01,  ..., -4.4162e-01,
          -3.9632e-01,  1.9090e-01],
         [-7.0736e-02, -2.6132e+00, -1.0513e+00,  ...,  1.0083e-03,
          -5.0300e-01,  4.0608e-01]]], device='cuda:0')
  File "/export/home2/shilin/nips24/VINE/vine/src/train.py", line 545, in <module>
    main(args)
  File "/export/home2/shilin/nips24/VINE/vine/src/train.py", line 293, in main
    encoded_image = watermark_encoder(img_a, timesteps, secret)
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/nips24/VINE/vine/src/vine_turbo.py", line 221, in forward
    model_pred = self.unet(x_enc, timesteps, encoder_hidden_states=self.fixed_a2b_emb_base,).sample.to(x.dtype)
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/nips24/VINE/diffusers/src/diffusers/models/unets/unet_2d_condition.py", line 1209, in forward
    sample, res_samples = downsample_block(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/nips24/VINE/diffusers/src/diffusers/models/unets/unet_2d_blocks.py", line 1288, in forward
    hidden_states = attn(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/nips24/VINE/diffusers/src/diffusers/models/transformers/transformer_2d.py", line 440, in forward
    hidden_states = block(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/nips24/VINE/diffusers/src/diffusers/models/attention.py", line 490, in forward
    attn_output = self.attn2(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/nips24/VINE/diffusers/src/diffusers/models/attention_processor.py", line 559, in forward
    return self.processor(
  File "/export/home2/shilin/nips24/VINE/diffusers/src/diffusers/models/attention_processor.py", line 1384, in __call__
    hidden_states = xformers.ops.memory_efficient_attention(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/xformers/ops/fmha/__init__.py", line 192, in memory_efficient_attention
    return _memory_efficient_attention(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/xformers/ops/fmha/__init__.py", line 295, in _memory_efficient_attention
    return _fMHA.apply(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/autograd/function.py", line 506, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/xformers/ops/fmha/__init__.py", line 41, in forward
    out, op_ctx = _memory_efficient_attention_forward_requires_grad(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/xformers/ops/fmha/__init__.py", line 323, in _memory_efficient_attention_forward_requires_grad
    out = op.apply(inp, needs_gradient=True)
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/xformers/ops/fmha/cutlass.py", line 175, in apply
    out, lse, rng_seed, rng_offset = cls.OPERATOR(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/_ops.py", line 502, in __call__
    return self._op(*args, **kwargs or {})
RuntimeError: Expected query.size(0) == key.size(0) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Traceback (most recent call last):
  File "/export/home2/shilin/nips24/VINE/vine/src/train.py", line 545, in <module>
    main(args)
  File "/export/home2/shilin/nips24/VINE/vine/src/train.py", line 293, in main
    encoded_image = watermark_encoder(img_a, timesteps, secret)
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/nips24/VINE/vine/src/vine_turbo.py", line 221, in forward
    model_pred = self.unet(x_enc, timesteps, encoder_hidden_states=self.fixed_a2b_emb_base,).sample.to(x.dtype)
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/nips24/VINE/diffusers/src/diffusers/models/unets/unet_2d_condition.py", line 1209, in forward
    sample, res_samples = downsample_block(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/nips24/VINE/diffusers/src/diffusers/models/unets/unet_2d_blocks.py", line 1288, in forward
    hidden_states = attn(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/nips24/VINE/diffusers/src/diffusers/models/transformers/transformer_2d.py", line 440, in forward
    hidden_states = block(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/nips24/VINE/diffusers/src/diffusers/models/attention.py", line 490, in forward
    attn_output = self.attn2(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/nips24/VINE/diffusers/src/diffusers/models/attention_processor.py", line 559, in forward
    return self.processor(
  File "/export/home2/shilin/nips24/VINE/diffusers/src/diffusers/models/attention_processor.py", line 1384, in __call__
    hidden_states = xformers.ops.memory_efficient_attention(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/xformers/ops/fmha/__init__.py", line 192, in memory_efficient_attention
    return _memory_efficient_attention(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/xformers/ops/fmha/__init__.py", line 295, in _memory_efficient_attention
    return _fMHA.apply(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/autograd/function.py", line 506, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/xformers/ops/fmha/__init__.py", line 41, in forward
    out, op_ctx = _memory_efficient_attention_forward_requires_grad(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/xformers/ops/fmha/__init__.py", line 323, in _memory_efficient_attention_forward_requires_grad
    out = op.apply(inp, needs_gradient=True)
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/xformers/ops/fmha/cutlass.py", line 175, in apply
    out, lse, rng_seed, rng_offset = cls.OPERATOR(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/_ops.py", line 502, in __call__
    return self._op(*args, **kwargs or {})
RuntimeError: Expected query.size(0) == key.size(0) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
