Steps:   0%|          | 1/14000000 [00:03<11855:41:19,  3.05s/it, train_chart/bit_acc=0.514, train_chart/image_loss=59.6, train_chart/loss=0.709, train_chart/loss_gan=0.332, train_chart/lpips_loss=0.993, train_chart/psnr=6.73, train_chart/secret_loss=0.709, train_chart/str_acc=0]Traceback (most recent call last):
[TRAINING] Warmup - using fixed input image for now!
  File "/export/home2/shilin/nips24/VINE/vine/src/train.py", line 545, in <module>
    main(args)
  File "/export/home2/shilin/nips24/VINE/vine/src/train.py", line 293, in main
    encoded_image = watermark_encoder(img_a, timesteps, secret)
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/nips24/VINE/vine/src/vine_turbo.py", line 220, in forward
    model_pred = self.unet(x_enc, timesteps, encoder_hidden_states=self.fixed_a2b_emb_base,).sample.to(x.dtype)
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/nips24/VINE/diffusers/src/diffusers/models/unets/unet_2d_condition.py", line 1209, in forward
    sample, res_samples = downsample_block(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/nips24/VINE/diffusers/src/diffusers/models/unets/unet_2d_blocks.py", line 1288, in forward
    hidden_states = attn(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/nips24/VINE/diffusers/src/diffusers/models/transformers/transformer_2d.py", line 440, in forward
    hidden_states = block(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/nips24/VINE/diffusers/src/diffusers/models/attention.py", line 490, in forward
    attn_output = self.attn2(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/nips24/VINE/diffusers/src/diffusers/models/attention_processor.py", line 559, in forward
    return self.processor(
  File "/export/home2/shilin/nips24/VINE/diffusers/src/diffusers/models/attention_processor.py", line 1384, in __call__
    hidden_states = xformers.ops.memory_efficient_attention(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/xformers/ops/fmha/__init__.py", line 192, in memory_efficient_attention
    return _memory_efficient_attention(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/xformers/ops/fmha/__init__.py", line 295, in _memory_efficient_attention
    return _fMHA.apply(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/autograd/function.py", line 506, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/xformers/ops/fmha/__init__.py", line 41, in forward
    out, op_ctx = _memory_efficient_attention_forward_requires_grad(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/xformers/ops/fmha/__init__.py", line 323, in _memory_efficient_attention_forward_requires_grad
    out = op.apply(inp, needs_gradient=True)
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/xformers/ops/fmha/cutlass.py", line 175, in apply
    out, lse, rng_seed, rng_offset = cls.OPERATOR(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/_ops.py", line 502, in __call__
    return self._op(*args, **kwargs or {})
RuntimeError: Expected query.size(0) == key.size(0) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
Traceback (most recent call last):
  File "/export/home2/shilin/nips24/VINE/vine/src/train.py", line 545, in <module>
    main(args)
  File "/export/home2/shilin/nips24/VINE/vine/src/train.py", line 293, in main
    encoded_image = watermark_encoder(img_a, timesteps, secret)
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/nips24/VINE/vine/src/vine_turbo.py", line 220, in forward
    model_pred = self.unet(x_enc, timesteps, encoder_hidden_states=self.fixed_a2b_emb_base,).sample.to(x.dtype)
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/nips24/VINE/diffusers/src/diffusers/models/unets/unet_2d_condition.py", line 1209, in forward
    sample, res_samples = downsample_block(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/nips24/VINE/diffusers/src/diffusers/models/unets/unet_2d_blocks.py", line 1288, in forward
    hidden_states = attn(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/nips24/VINE/diffusers/src/diffusers/models/transformers/transformer_2d.py", line 440, in forward
    hidden_states = block(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/nips24/VINE/diffusers/src/diffusers/models/attention.py", line 490, in forward
    attn_output = self.attn2(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home2/shilin/nips24/VINE/diffusers/src/diffusers/models/attention_processor.py", line 559, in forward
    return self.processor(
  File "/export/home2/shilin/nips24/VINE/diffusers/src/diffusers/models/attention_processor.py", line 1384, in __call__
    hidden_states = xformers.ops.memory_efficient_attention(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/xformers/ops/fmha/__init__.py", line 192, in memory_efficient_attention
    return _memory_efficient_attention(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/xformers/ops/fmha/__init__.py", line 295, in _memory_efficient_attention
    return _fMHA.apply(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/autograd/function.py", line 506, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/xformers/ops/fmha/__init__.py", line 41, in forward
    out, op_ctx = _memory_efficient_attention_forward_requires_grad(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/xformers/ops/fmha/__init__.py", line 323, in _memory_efficient_attention_forward_requires_grad
    out = op.apply(inp, needs_gradient=True)
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/xformers/ops/fmha/cutlass.py", line 175, in apply
    out, lse, rng_seed, rng_offset = cls.OPERATOR(
  File "/export/home2/shilin/anaconda3/envs/vine/lib/python3.10/site-packages/torch/_ops.py", line 502, in __call__
    return self._op(*args, **kwargs or {})
RuntimeError: Expected query.size(0) == key.size(0) to be true, but got false.  (Could this error message be improved?  If so, please report an enhancement request to PyTorch.)
